\documentclass{sigchi}

% Use this section to set the ACM copyright statement (e.g. for
% preprints).  Consult the conference website for the camera-ready
% copyright statement.

% Copyright   
\CopyrightYear{2016}
%\setcopyright{acmcopyright}
\setcopyright{acmlicensed}
%\setcopyright{rightsretained}
%\setcopyright{usgov}
%\setcopyright{usgovmixed}
%\setcopyright{cagov}
%\setcopyright{cagovmixed}
% DOI
\doi{http://dx.doi.org/10.475/123_4}
% ISBN
\isbn{123-4567-24-567/08/06}
%Conference
\conferenceinfo{CHI'16,}{May 07--12, 2016, San Jose, CA, USA}
%Price
\acmPrice{\$15.00}

% Use this command to override the default ACM copyright statement
% (e.g. for preprints).  Consult the conference website for the
% camera-ready copyright statement.

%% HOW TO OVERRIDE THE DEFAULT COPYRIGHT STRIP --
%% Please note you need to make sure the copy for your specific
%% license is used here!
% \toappear{
% Permission to make digital or hard copies of all or part of this work
% for personal or classroom use is granted without fee provided that
% copies are not made or distributed for profit or commercial advantage
% and that copies bear this notice and the full citation on the first
% page. Copyrights for components of this work owned by others than ACM
% must be honored. Abstracting with credit is permitted. To copy
% otherwise, or republish, to post on servers or to redistribute to
% lists, requires prior specific permission and/or a fee. Request
% permissions from \href{mailto:Permissions@acm.org}{Permissions@acm.org}. \\
% \emph{CHI '16},  May 07--12, 2016, San Jose, CA, USA \\
% ACM xxx-x-xxxx-xxxx-x/xx/xx\ldots \$15.00 \\
% DOI: \url{http://dx.doi.org/xx.xxxx/xxxxxxx.xxxxxxx}
% }

% Arabic page numbers for submission.  Remove this line to eliminate
% page numbers for the camera ready copy
% \pagenumbering{arabic}

% Load basic packages
\usepackage{balance}       % to better equalize the last page
\usepackage{graphics}      % for EPS, load graphicx instead 
\usepackage[T1]{fontenc}   % for umlauts and other diaeresis
\usepackage{txfonts}
\usepackage{mathptmx}
\usepackage[pdflang={en-US},pdftex]{hyperref}
\usepackage{color}
\usepackage{booktabs}
\usepackage{textcomp}

% Some optional stuff you might like/need.
\usepackage{microtype}        % Improved Tracking and Kerning
% \usepackage[all]{hypcap}    % Fixes bug in hyperref caption linking
\usepackage{ccicons}          % Cite your images correctly!
% \usepackage[utf8]{inputenc} % for a UTF8 editor only

% If you want to use todo notes, marginpars etc. during creation of
% your draft document, you have to enable the "chi_draft" option for
% the document class. To do this, change the very first line to:
% "\documentclass[chi_draft]{sigchi}". You can then place todo notes
% by using the "\todo{...}"  command. Make sure to disable the draft
% option again before submitting your final document.
\usepackage{todonotes}

% Paper metadata (use plain text, for PDF inclusion and later
% re-using, if desired).  Use \emtpyauthor when submitting for review
% so you remain anonymous.

\def\plaintitle{Gait Prediction One Step Ahead \\ for Real Time Gait Guidance}
\def\plainauthor{First Author, Second Author, Third Author,
  Fourth Author, Fifth Author, Sixth Author}
\def\emptyauthor{}
\def\plainkeywords{Authors' choice; of terms; separated; by
  semicolons; include commas, within terms only; required.}
\def\plaingeneralterms{Documentation, Standardization}

% llt: Define a global style for URLs, rather that the default one
\makeatletter
\def\url@leostyle{%
  \@ifundefined{selectfont}{
    \def\UrlFont{\sf}
  }{
    \def\UrlFont{\small\bf\ttfamily}
  }}
\makeatother
\urlstyle{leo}

% To make various LaTeX processors do the right thing with page size.
\def\pprw{8.5in}
\def\pprh{11in}
\special{papersize=\pprw,\pprh}
\setlength{\paperwidth}{\pprw}
\setlength{\paperheight}{\pprh}
\setlength{\pdfpagewidth}{\pprw}
\setlength{\pdfpageheight}{\pprh}

% Make sure hyperref comes last of your loaded packages, to give it a
% fighting chance of not being over-written, since its job is to
% redefine many LaTeX commands.
\definecolor{linkColor}{RGB}{6,125,233}
\hypersetup{%
  pdftitle={\plaintitle},
% Use \plainauthor for final version.
%  pdfauthor={\plainauthor},
  pdfauthor={\emptyauthor},
  pdfkeywords={\plainkeywords},
  pdfdisplaydoctitle=true, % For Accessibility
  bookmarksnumbered,
  pdfstartview={FitH},
  colorlinks,
  citecolor=black,
  filecolor=black,
  linkcolor=black,
  urlcolor=linkColor,
  breaklinks=true,
  hypertexnames=false
}

% create a shortcut to typeset table headings
% \newcommand\tabhead[1]{\small\textbf{#1}}

% End of preamble. Here it comes the document.
\begin{document}

\title{\plaintitle}

\numberofauthors{3}
\author{%
  \alignauthor{Leave Authors Anonymous\\
    \affaddr{for Submission}\\
    \affaddr{City, Country}\\
    \email{e-mail address}}\\
  \alignauthor{Leave Authors Anonymous\\
    \affaddr{for Submission}\\
    \affaddr{City, Country}\\
    \email{e-mail address}}\\
  \alignauthor{Leave Authors Anonymous\\
    \affaddr{for Submission}\\
    \affaddr{City, Country}\\
    \email{e-mail address}}\\
}

\maketitle
%UPDATED---\today. This sample paper describes the formatting
%requirements for SIGCHI conference proceedings, and offers
%recommendations on writing for the worldwide SIGCHI
%readership. Please review this document even if you have submitted
%to SIGCHI conferences before, as some format details have changed
%relative to previous years. Abstracts should be about 150 words and
%are required.
%
%
%This format is to be used for submissions that are published in the
%conference proceedings. We wish to give this volume a consistent,
%high-quality appearance. We therefore ask that authors follow some
%simple guidelines. You should format your paper exactly like this
%document. The easiest way to do this is to replace the content with
%your own material.  This document describes how to prepare your
%submissions using \LaTeX.
%
%\section{Page Size and Columns}
%On each page your material should fit within a rectangle of 7 $\times$
%9.15 inches (18 $\times$ 23.2 cm), centered on a US Letter page (8.5
%$\times$ 11 inches), beginning 0.85 inches (1.9 cm) from the top of
%the page, with a 0.3 inches (0.85 cm) space between two 3.35 inches
%(8.4 cm) columns. Right margins should be justified, not
%ragged. Please be sure your document and PDF are US letter and not A4.
%
%\section{Typeset Text}
%The styles contained in this document have been modified from the
%default styles to reflect ACM formatting conventions. For example,
%content paragraphs like this one are formatted using the Normal style.
%
%\LaTeX\ sometimes will create overfull lines that extend into columns.
%To attempt to combat this, the \texttt{.cls} file has a command,
%\texttt{{\textbackslash}sloppy}, that essentially asks \LaTeX\ to
%prefer underfull lines with extra whitespace.  For more details on
%this, and info on how to control it more finely, check out
%{\url{http://www.economics.utoronto.ca/osborne/latex/PMAKEUP.HTM}}.
%%%


\begin{abstract}

%% abstract should be about 150 words (SIGCHI)
%ヒトの歩行運動は，突発的な感覚入力への姿勢反射応答の潜時が約２歩であることが知られている．
%そのため歩行を実時間で誘導するためには，現在の歩行運動状態から２歩先行した歩行運動を実時間で予測し続ける必要がある．
%そこで本研究では多層パーセプトロンを用いた実時間歩行運動予測を行い，
%直進・右左折を含む5種の歩行運動に対し，１歩先行した歩行予測を実現したので報告する．
Gait involving subconscious postural reflex can be guided using sensory illusion so that the user is not aware of such illusion. In fact, many previous studies using illusionary sensory feedback to the user have realized subconscious gait guidance. However, an approximately two-step latency in attitude reflection response after a sudden sensory input may affect accurate gait guidance in real time\cite{1492799}. For example, it is too late to give sensory feedback to make the user turn left once he or she starts to turn right. Thus, predicted gait movement must be two steps ahead of the current gaiting in real time. This paper proposes a gait prediction method using a multilayered perceptron as a predictor for gait motion datasets, including five kinds of gait motion such as straight ahead, right turn, and left turn. The evaluation results show that the proposed method achieved gait prediction that was one step ahead in the numerical experiment.

\end{abstract}

\category{H.5.m.}{Information Interfaces and Presentation
  (e.g. HCI)}{Miscellaneous} \category{See
  \url{http://acm.org/about/class/1998/} for the full list of ACM
  classifiers. This section is required.}{}{}

\keywords{\plainkeywords}

\section{Introduction}
% take sympathy in easy way
% Editaged Sept 16, 2017
How do you visit a place you have never been before by foot? You may carry a printed map in your bag or bookmark the location in your cell phone\cite{maruyama2002portable} so as to not lose your way before reaching your destination. Or you may finally open Google Maps to follow the directions from the station just after you get off a train. In any case, you will drop your gaze to the map several times so as to not lose your way. This is a typical guidance scenario for pedestrians.

The point described above is that you need to pay attention to the map. In terms of navigation, the direction towards which you should head is given explicitly or, in other words, consciously.
This means that, as several studies have pointed out~\cite{Ghaem1997,PSYP:PSYP1043,1276842},
%% needs to be revised
 the typical navigation sequence places a mental load upon you. How can we get rid of this load? This question is the reason why these previous studies propose subconscious navigation using sensory illusion\cite{Tanikawa2012,%VectionHMD
TJP:TJP931,TJP:TJP1033,7460029,7989977,BENT2000157,Britton1993,campbell2000headset,campbell1998multimodal}.% GVS Patient

To promote the idea, here is an ultimate guidance scenario: even though you do not need to remember the route or refer to any map along the way, you can go to places you have never been before; in addition, you never notice when and how the guidance system supports you. You can arrive on foot without conscious awareness, as if you were walking your usual route, although you do not know the actual route. It seems as if you know the entire route; however, no conscious or verbal information is given to you. This is a kind of magical future scenario.

How can humans and computers interact with each other in this case? Needless to say, it is difficult to physically direct and control walking in daily life since it often requires powerful actuators to move heavy parts of our bodies~\cite{doi:10.3109/03093648709078194,DOMINGO2009464}. On the other hand, since gait has a control cycle including sensory input and movement output, we can say that sensory feedback can control gait movements, as described before. Providing sensory illusion is a relatively practical way to control gait subconsciously because our bodies have an automatic response to sensory inputs, which do not require high-power physical actuation~\cite{Watanabe2010,Watanabe:2005:SII:1152399.1152406,Jones2008,Imamura:2011:HHW:2048259.2048265, Turchet2015, 7460029}. Such a response is called "postural reflex," which occurs subconsciously. Therefore, alternative illusion sensory feedback is useful to induce a user's behavior. In terms of pedestrians' directional guidance, illusion sensory input can induce postural sway to the one side, which results in walking route change. 


Above all, although it sounds simple that sensory input economically induces gait guidance, we need to consider response latency from the time the sensory input is given to the time when body movement occurs. This aspect is critical for gait guidance in real time: for instance, it is too late to give sensory feedback telling the user to turn left once he or she has already begun turning right. In terms of system control, a large time delay in the closed loop usually makes control systems unstable, oscillated, or divergent. It is known that gait includes a two-step latency period with regard to sensory input. Therefore, gait guidance requires that sensory illusion be provided two-steps earlier than the current gait. This also requires the system to predict future gait two-step earlier in real time, in order to decide the amount of sensory feedback to be given to the user. This is an essential motivation to realize real-time gait prediction.


What kind of cues obtained from the user can be used to anticipate future gait? This question equals to make a brain machine interface (BMI) to read what you will do or what you are thinking in your brain. However, BMIs require you to maintain a stable posture without making body movements, which brings electrical noises affecting very low voltage brain oriented signal\cite{PFURTSCHELLER2006145,OLNEY19859}. For example, the one measuring change of skin surface voltage is too sensitive on conductance change between the electrode and the skin; the one recording blood flow changes near the skull also weakens upon changing the probe posture and location on your skull. Obviously, such functional magnetic resonance imaging (fMRI) is not suitable to observe brain activity while walking. In short, these typical BMI methods have highly strict constraints to be able to achieve stable brain activity measurements. Above all, typical BMI methods are unable to identify  where you are going to go.

By changing our point of view, we can say that our body movement reflects\cite{VANEMMERIK19961175} our brain activity, including movement planning for the near future\cite{MORRIS1973729,ZIJLSTRA1997249}.%NEED CHECK
 Actually, several studies indicate that acceleration of your palm says what kind of gesture you will show next, e.g. paper, rock, and scissors. It is worth focusing on only knowing how your body moves implicitly; this kind of brain and body activity occurs subconsciously. Therefore, we can say that your body movement conveys not only what you are thinking but also what you will do in the near future. In other words, it seems possible to construct a kind of BMI through body movement. This feature does fit the process of observing gait. At this time, in terms of obtaining brain activity, body movement becomes not scary, but valuable. It may be possible to estimate future gait from current gait. If possible, the real-time gait guidance method would have the ability to know future gait several steps ahead, which could also advance illusion sensory feedback several steps ahead as well. 
Assuming that the current body movement involves cues of future gait, here is an open question of this paper: How do we extract future gait and how further ahead does the possibility of estimating it lie?

Assuming that the current body movement involve the cue of the future gait, here is an open question of this paper: how to extract the future gait; how further ahead is could be possible to estimate it?

neural network\cite{LIU1999391}

vection\cite{JPR:JPR167,pmid7845766,pmid25774143,Furukawa:2011:VFP:1959826.1959845}

%	illusion human interface citation x 15
%	implicit impact -> wearable x 10
%	knowledge less learning
%research question
%	gait prediction (original point)
%	machine learning / svm / deep learning 
%	categorical data vs continuous numerical data / classification vs regression
%	authentication vs 
%	sillouette vs physical movement
%	sagital plane
%	without understanding return just real data!
%	position / acceleration / velocity why? comparison!
%	why velocity?
%	marker number comparison
%	future implementation and advantage


It is known that the walking motion of humans is about 2 steps in latency of attitude reflection response to sudden sensory input\cite{bib01}.
%ヒトの歩行運動は，突発的な感覚入力への姿勢反射応答の潜時が約２歩であることが知られている\cite{bib01}．
So, in order to induce walking in real time, it is necessary to continue to predict walking exercise two steps ahead of the current locomotion state in real time.
%そのため歩行を実時間で誘導するためには，現在の歩行運動状態から２歩先行した歩行運動を実時間で予測し続ける必要がある．
Therefore, in this research we report real time walking motion prediction using multilayered perceptron and realized walking prediction one step ahead of five kinds of walking exercise including straight ahead, right turn and left turn.
%そこで本研究では多層パーセプトロンを用いた実時間歩行運動予測を行い，
%直進・右左折を含む5種の歩行運動に対し，１歩先行した歩行予測を実現したので報告する．

%本研究の目的は，歩行の予測可能性を示すことにあるため，任意の歩行運動を対象とするのではなく，予め明示的に設計された経路を歩行した際の歩行運動を対象とする．そこで本研究の問題を「現在時刻の歩行運動から$\Delta t$秒先の歩行運動をどの程度予測可能か」と設定する．ここで本研究の主目的は経路案内を達成するための歩行誘導であるため，予測対象である「歩行運動」は頭部の移動軌跡が得られれば十分であると考える．
The purpose of this study is to show the predictability of walking, we do not target any arbitrary walking movement. As a first step, we focus on walking movement explicitly designed route in advance. Therefore, we set the problem of this research as "how much can we predict the walking motion $\Delta t$ seconds earlier from the walking motion at the current time?" The main objective of this research is walking guidance to achieve route guidance, we believe that it is sufficient to obtain the movement locus of the head, "walking motion" as the prediction target.

%本研究における予測対象は物理量を有する身体運動であるべきであって，右折，左折といった名義尺度ではないとする．これは歩行予測と誘導を実時間で実現するためには，制御対象である身体運動を物理量として取り扱う必要があることに起因する．
It is assumed that the object to be predicted in this study should be physical movement with physical quantity, not a nominal scale such as a right turn, a left turn. This is due to the fact that it is necessary to treat body motion to be controlled as a physical quantity in order to realize walking prediction and guidance in real time. 

%本研究では連続運動としての相関が現時刻・先行時刻間で低下したとしても，先行時刻における運動を推定するに足る情報量が現在時刻に内包されているのならば，推定精度が十分高いことが期待できる先行時間幅が存在すると仮定している．
{\bf  *****add reason*****} Even if the correlation as continuous motion declines between the current time and the preceding time, if the information amount enough to estimate the motion at the preceding time is included in the current time, the estimation accuracy is sufficiently high It is assumed that there is a preceding time width that can be expected.

%  歩行運動計測と歩行運動のモデル化
\section{Modeling}
\subsection{Measurement of walking motion} %歩行運動の計測
\label{subsec-nac}

%まず取り扱う物理量の選定であるが，本稿では歩行運動を表現する物理量として速度を用いている．これは歩行運動は連続した周期運動であるためである．つまり時刻$t$において観測される身体各部位の速度は，周期$T$後に再び観測されるという仮説が成立しうる利点がある．さらにこの仮説は歩行位置によらず成立するため，速度という物理的特徴量は，空間内の任意の位置を移動する歩行者を対象とした実時間歩行運動予測に適した特徴を与える．
First, selection of physical quantities to be handled will be described. Speed is used as a physical quantity expressing walking motion. This is because the walking motion is a continuous periodic motion. That is, the hypothesis that the velocity of each part of the body observed at the time $ t $ is observed again after the period $ T $. Furthermore, since this hypothesis is established regardless of the walking position, the physical feature quantity of speed gives characteristics suitable for prediction of real time walking motion for pedestrians moving at arbitrary positions in the space. {\bf  *****add reason*****}

%歩行運動を計測するためのマーカ配置として，図\ref{fig:marker}に示したHelen Hayers配置を用いた．nac社製Kestrel(220万画素)を8台用いて300fpsにて撮影を行なった．MAC3D System Cortexを用いて計測された25点の位置$\{p_x,p_y,p_z\}$データについて欠損データの補間処理，カットオフ周波数6Hzでのローパスフィルタ処理を行なった．さらに後退差分法による25点マーカの速度ベクトル$\{v_x,v_y,v_z\}$を導出した．
Helen Hayers arrangement shown in Figure~\ref{fig:marker} was used as a marker arrangement for measuring walking motion. We shot at 300 fps with 8 Kestrel (2.2 million pixels) made by nac company. Interpolation processing of missing data and low pass filter processing at cutoff frequency of 6 Hz were performed on 25 positions $\{p_x, p_y, p_z \}$ measured using MAC3D System Cortex. Furthermore, the velocity vector $ \{v_x, v_y, v_z \} $ of the 25 point marker by the backward difference method is derived.

\begin{figure}
\centering
  \includegraphics[width=30mm]{fig/marker.eps}
  \caption{Marker arrangement (Helen Hayers)}~ \label{fig:marker}
\end{figure}


%\subsection{歩行条件}
\subsection{Walking condition}

%定量的に予測性能を評価するために，経路条件として「直進，90度右折，90度左折，45度右折，45度左折」の5条件を設定した．歩行距離は1試行につき6[m]であり，その内訳は始点から3mの直進区間を経て右左折もしくは直進区間としてさらに3[m]である．5条件の歩行経路を明示するため床に印を貼り，通常の歩行速度や歩幅で男性被験者1名に歩行させた．
In order to quantitatively evaluate the prediction performance, five conditions of "straight ahead, turn 90 degrees to the right, turn 90 degrees to the left, turn 45 degrees to the right and turn 45 degrees to the left" were set as the route condition. The walking distance is 6 [m] per trial, and the breakdown has 3 [m] as a right / left turn or a straight traveling section after going through a straight section of 3 [m] from the start point. A mark was put on the floor  in order to clearly show the walking path of 5 conditions. One male participant waked with normal walking speed and stride.

%計測データの中から学習データセットとして用いた頭部軌跡を図\ref{fig:training-data}に示す．同図は図\ref{fig:marker}中の黒矢印として示した頭頂部の軌跡であり，5条件を各2回分の歩行データを含む．経路5条件に従って，水平面内の原点付近で右左折をしている様子が確認できる．垂直面内の脈動は頭部の上下動を表している．第\ref{subsec-nac}節の通り，1試行のデータは各時刻あたり全25点分のマーカの速度ベクトル(3次元)の計75点が300[fps]で記録された時系列データである．
The head trajectory used as the training data set from the measurement data is shown in Figure~\ref{fig:training-data}. This figure is the trajectory of the top of the head shown as a black arrow in Figure~\ref{fig:marker}, and 5 conditions include walking data for each two times. According to the route 5 condition, it can be seen that the vehicle is turning right or left near the origin in the horizontal plane. The pulsation in the vertical plane represents the vertical movement of the head. As shown in the \ref{subsec-nac} section, the data of one trial is time series data recorded at a total of 75 points of the velocity vector (three dimensions) of markers of all 25 points per time at 300 [fps] is there.


%\begin{figure}[tb]
%  \begin{center}
%    \includegraphics*[width=80mm]{fig/TRAINING-DATA.eps}
%  \end{center}
%  \vspace*{-10mm}
%  \caption{学習データ群の頭頂部マーカ軌跡(図\ref{fig:marker}黒矢印)}
%  \label{fig:training-data}
%\end{figure}


\begin{figure}
\centering
  \includegraphics[width=80mm]{fig/TRAINING-DATA.eps}
  \caption{Parietal marker (appeared in Figure~\ref{fig:marker} black arrow) locus of learning data group}~ 
    \label{fig:training-data}
\end{figure}


%\subsection{入出力データ群のモデル化}
\subsection{Modeling of input / output data group}
\label{projection}

%予測器への入出力データである歩行運動のデータ群を用いて，歩行運動推定問題をモデル化する．
We model the walking motion estimation problem using data group of walking motion which is input / output data to predictor.

%今時刻$t$におけるマーカ$m$の速度を$\check{v}_{m,t} $と定義し，全マーカの集合を$X(t) \in \mathbb{R}^{1 \times 75}$，頭頂部マーカのみの集合を$Y(t) \in \mathbb{R}^{1 \times 3}$と定義する．また現在時刻から予測対象の先行時刻までの幅を「先行時間幅$\Delta t$」と表す．ここで本研究の問題は次のように定式化される．すなわち，$\Delta t = 0 $[s] ならば，「現在の歩行運動から現在の頭頂部運動の予測」問題を解けば良い．これは写像$f_{\Delta t = 0}: X(t) \rightarrow Y(t)$を推定するモデル同定と等価である．同様に$\Delta t = 0.5 $[s] ならば「現在の歩行運動から0.5[s]先の頭頂部運動の予測」となる写像$f_{\Delta t = 0.5}: X(t) \rightarrow Y(t+\Delta t)$の同定問題に帰着される．
Define the speed of the marker $m$ at the current time $t$ as $\check{v}_{m, t}$. The set of all markers is $X(t)\in\mathbb{R}^{1 \times 75} $. The set of only parietal markers is $ Y(t)\in\mathbb {R}^{1\times 3}$. Also, the width from the current time to the preceding time of the prediction target is expressed as "advance time width $\Delta t$". Here, the problem of this research is formulated as follows. That is, if $\Delta t = 0$ [s], you can solve the problem of "prediction of current head motion from current walking motion". This is equivalent to model identification to estimate the mapping $ f_ {\Delta t = 0}: X (t) \rightarrow Y (t) $. Likewise, if $ \Delta t = 0.5 $ [s], this results in the identification problem of then a mapping $ f_ {\Delta t = 0.5}: X (t) \rightarrow Y (t + \Delta t) $.

%期待される予測精度は，先行時間幅が増加するに伴い低下すると考えられる．これは連続周期運動である歩行の運動特徴量としての相関が，そこで本稿では計測したデータから求めた2歩分の時間1.1[s]を基準歩行周期とみなし，同条件として$\Delta t = \{0.0, \  0.5, \ 1.1\}$ [s]の3条件を設定した．これは歩数表現でそれぞれ${0, 1, 2}$歩先の予測に対応する．予測精度は$\Delta t = 0$ が最も高く，$\Delta t = 1.1$ が最も低いと推定される．しかし推定精度が低くとも，例えば，右左折の判断に足る運動予測の可能性を明らかにすることに本稿の主眼がある．
The expected prediction accuracy is considered to decrease as the advance time width increases. Considering the correlation as the motion feature quantity of walking, which is a continuous cycle motion, even if the correlation as the continuous motion decreases between the current time and the preceding time, the amount of information sufficient to estimate the motion at the preceding time is currently If it is included in the time, it is assumed that there is a preceding time width that can be expected that the estimation accuracy is sufficiently high. Therefore, in this paper, we consider the time 1.1 [s] of two steps obtained from the measured data as the reference walking cycle, and as $ \Delta t = \{0.0, \ 0.5, \ 1.1 \} $ [s] as the same condition Conditions were set. This corresponds to the prediction of $ \{0, 1, 2\} $ step by step number representation. The prediction accuracy is estimated to be the highest for $ \Delta t = 0 $, and $ \Delta t = 1.1 $ is the lowest. However, even if the estimation accuracy is low, for example, the main purpose of this paper is to clarify the possibility of motion prediction that is sufficient for right / left turn judgment.

%\section{予測器設計と歩行運動学習}%%%%%%%%%%%%%%%%%%%%
\section{Predictor design and walking motion learning}%%%%%%%%%%%%%%%%%%%%

%\subsection{予測器設計}
\subsection{Predictor design}


%予測器は図\ref{fig:dbn}に示すDeep belief networkを用いた．細胞数は入力層，隠れ層，出力層それぞれ75，100，3である．入力層に現在時刻$t$における25点分のマーカの速度ベクトル($X(t) \in \mathbb{R}^{1 \times 75}$)を与え，出力層に先行時刻幅$\Delta t$先の頭頂部マーカの速度ベクトル($Y(t + \Delta t) \in \mathbb{R}^{1 \times 3}$)を推定させる．活性化関数はシグモイド関数(sigm)，出力関数は恒等写像関数(linear)である．
For the predictor, we used the Deep belief network shown in Figure~\ref{fig:dbn}. The number of cells is 75, 100, 3 for the input layer, the hidden layer, and the output layer respectively. We give the input layer the velocity vector ($ X (t) \in \mathbb {R}^{1 \times 75} $) of the marker for 25 points at the current time $ t $ and add the preceding time width $ \Delta t $ Infer the velocity vector ($ Y (t + \Delta t) \in \mathbb {R} ^{1 \times 3} $) of the top of the head marker. The activation function is a sigmoid function (sigm), and the output function is an identity mapping function (linear).

%\begin{figure}[tb]
%  \begin{center}
%    \includegraphics*[width=60mm]{fig/DBN_3layers.eps}
%  \end{center}
%  \vspace*{-6mm}
%  \caption{Deep belief network}
%  \label{fig:dbn}
%\end{figure}

\begin{figure}
\centering
  \includegraphics[width=65mm]{fig/DBN_3layers.eps}
  \caption{Deep belief network}~\label{fig:dbn}
\end{figure}


\begin{figure}
\centering
  \includegraphics[width=80mm]{fig/DBN_3layers_timeshift.eps}
  \caption{Deep belief network}~\label{fig:dbn_timeshift}
\end{figure}


%\subsection{正規化}
\subsection{Normalization}

%学習のための前処理として，入出力データの正規化を行う．
As preprocessing for learning, input / output data is normalized.

%まず第\ref{projection}節で定義した写像則に従い教師データ群を作成し，$X(t) \in \mathbb{R}^{1 \times 75}, Y(t + \Delta t) \in \mathbb{R}^{1 \times 3}$をそれぞれ得る．これらの集合は速度の実測値 $\check{v}_{m,t}$ を持つ．ここで$m$はマーカやデカルト座標系$\{ x, y, z\}$に区別なく付与される系列番号であり，$X$，$Y$に対しそれぞれ$1 \leq m_X \leq 75$，$1 \leq m_Y \leq 3$を与える．正規化とは，全時刻域$(1 \leq t \leq N)$で系列$m$の集合の平均を 0 標準偏差を1に変換することである．
First, create a training data group according to the mapping rule defined in the section \ref{projection}, and create $ X (t) \in \mathbb {R} ^ {1 \times 75}, Y (t + \Delta t) \in \mathbb {R} ^ {1 \ times 3} $ respectively. These sets have actual measured values of speed $ \check {v}_{m, t} $. Here, $ m $ is a sequence number given without distinction to the marker or Cartesian coordinate system $ \{x, y, z \} $, and $ 1 \leq m_X \leq 75$ and $ 1 \leq m_Y \leq 3 $ for each $ X $ and $ Y $. Normalization is to convert the average of the set of series $ m $ in all time zones $ (1 \leq t \leq N) $ to zero and to convert standard deviation to 1.

%具体的には，系列$m$内平均$\overline{\check{v}_{m}} $を式(\ref{eq:average})で求める．ただし$C$は全条件数であり，$n_c$は各条件$c$が含む時間ステップ数である．
For instance, find the average $ \overline {\check {v}_{m}} $ of the series $ m $ within the formula (\ref{eq:average}). Where $ C $ is the total number of conditions and $ n_c $ is the number of time steps included in each condition $ c $.

% m : marker index number
% Tn = all seconds
% average 
\begin{equation}
\overline{\check{v}_{m}} = \frac{1}{N}\sum^{N}_{t=1}\check{v}_{m,t} 
 \hspace{3mm} where  \hspace{3mm}
N=\sum^{C}_{c=1} n_c 
\label{eq:average}
\end{equation}

%次に，系列$m$内の標準偏差$\check{s}_m$を式(\ref{eq:standardDeviation})で求める．
Next, find the standard deviation $ \check {s}_m $ in the sequence $ m $ by the expression (\ref{eq:standardDeviation}).

% standard deviation
\begin{equation}
  \check{s}_m = \sqrt{ \frac{1}{N-1}\sum^{N}_{t=1} ( \check{v}_{m,t} - \overline{\check{v}_m} ) ^2} 			
\label{eq:standardDeviation}
\end{equation}

% 最後に，系列$m$は式(\ref{eq:regularization})により正規化された$ v_{m,t} $を得る．
Finally, the sequence $ m $ gets $ v_{m, t} $ normalized by the expression (\ref{eq:regularization}).

% regularization
\begin{equation}
  v_{m,t} = \frac{\check{v}_{m,t} - \overline{\check{v}_{m}}}{\check{s}_m} 
  \label{eq:regularization}
\end{equation}


%\subsection{予測実験}
\subsection{Prediction experiment}
%現在時刻の速度入力マーカ25点$X(t) \in \mathbb{R}^{1 \times 75}$に対する頭頂部速度$Y(t + \Delta t) \in \mathbb{R}^{1 \times 3}$を前述の通り正規化し教師データとして学習させた．教師データ長は，先行時間幅$\Delta  t =\{0.0, \ 0.5,\  1.1\} $[s]ごとにそれぞれ12976, 11476,  9676である．バッチサイズは各先行時間幅ごとにそれぞれ12976, 11476, 9676とし，学習回数を 2000回とし学習させた．学習時の各種パラメータは脚注\footnote{Learning rate  4, momentum 0.5, dropoutFraction 0.5, inputZeroMaskedFraction 0.2, weightMaxL2norm 15}に示す．以上の手続きから，各先行時間幅3条件における予測器$f_{\Delta t = \{0.0, 0.5, 1.1\}}$をそれぞれ3つ得た．
Speed input marker of current time 25 points $ X (t) \in \mathbb {R} ^ {1 \times 75} $ head bit velocity for $ \in \mathbb {R}^{ 1 \times 3} $ were normalized and learned as teacher data as described above. The teacher data length is 12976, 11476, 9676 for the preceding time width $ \Delta t = \{0.0, \ 0.5, \ 1.1 \} $ [s] respectively. The batch size was set to 12976, 11476, 9676 for each preceding time width, and learning was done with 2000 learning times. Various parameters at learning are shown in footnote \footnote{Learning rate 4, momentum 0.5, dropout Fraction 0.5, input ZeroMaskedFraction 0.2, weightMaxL 2 norm 15}. From the above procedure, we have obtained three predictors $ f_{\Delta t = \{0.0, 0.5, 1.1 \}} $ for each preceding time width of 3 conditions.

%評価用データ群として，教師データ群とは異なるデータ群を用いた．ただし評価用データ群も同一被験者から教師データ群と同一日に計測したものである．
A data group different from the teacher data group was used as the evaluation data group. However, the evaluation data group was also measured on the same day as the teacher data group from the same subject.


%\section{予測結果}%%%%%%%%%%%%%%%%%%%%
\section{Prediction Result}%%%%%%%%%%%%%%%%%%%%

%\subsection{予測された速度の時系列評価}
\subsection {Time series evaluation of the predicted speed}

%実験結果を図\ref{fig:velocity-result}に示す．同図は横軸を時間，縦軸を歩行者の初期位置における左右方向の頭頂部の速度成分とした時系列推定結果を示している．同図は世界座標系で表現された速度であるため，$\Delta t = 0.0$[s]の $t=7$[s]付近以降のように大きく負の値をとる場合は，歩行者は右折したことを表している．
Experimental results are shown in Figure~\ref{fig:velocity-result}. In the same figure, the time series estimation result is shown in which the horizontal axis is time and the vertical axis is the velocity component of the top of the pedestrian at the initial position of the pedestrian. Since this figure is the speed expressed in the world coordinate system, when taking a large negative value like $ t = 7 $ [s] in $ \Delta t = 0.0 $ [s], the pedestrian It means that you made a right turn.

%\begin{figure*}[tb]
%  \begin{center}
%    \includegraphics*[width=180mm]{fig/velocity.eps}
%  \end{center}
%  \vspace*{-10mm}
%  \caption{$x$軸方向の速度予測結果($\Delta t$は先行時間幅を表す)}
%  \label{fig:velocity-result}
%\end{figure*}

\begin{figure*} 
\centering
  \includegraphics[width=180mm]{fig/velocity.eps}
  \caption{$ x $ speed prediction result in the axial direction ($ \Delta t $ represents the preceding time width)}~\label{fig:velocity-result}
\end{figure*}

 \begin{figure*}
\centering
  \includegraphics[width=180mm]{fig/Velocity_marker_diff.eps} \hspace{25mm} 
  \caption{$ x $ speed prediction result in the axial direction ($ \Delta t $ represents the preceding time width)}~\label{fig:velocity-result}
\end{figure*}


\begin{figure*}
\centering
  \includegraphics[width=160mm]{fig/timeshift.eps}
  \caption{$ x $ speed prediction result in the axial direction ($ \Delta t $ represents the preceding time width)}~\label{fig:velocity-result}
\end{figure*}




%図\ref{fig:velocity-result}のいずれのプロットも評価用データ群に関するものであり，青い一点鎖線のGround Truth(期待する結果)が$Y(t+\Delta t)$，太い橙色のPredicted(予測された結果)が$f_{\Delta t}(X(t))$，細い橙色のCurrent Velocity(入力層に与えられた現時刻での速度)が$X(t)$をそれぞれ示している．予測器の同定に十分成功していれば予測結果$f_{\Delta t}(X(t))$ が期待する結果$Y(t + \Delta t)$に漸近する．
Both plots of the Figure~\ref{fig:velocity-result} relate to the data group for evaluation, and the blue dashed line Ground Truth (expected result) is $ Y (t + \Delta t) $, the thick orange Predicted (Predicted result) is $ f_ {\Delta t} (X (t)) $, and the thin orange Current Velocity (the speed at the current time given to the input layer) is $ X (t) $ ing. The prediction result $ f_ {\Delta t} (X (t)) $ asymptotically approaches the expected result $ Y (t + \Delta t) $ if the predictor identification is sufficiently successful.

%まず図\ref{fig:velocity-result}上段の先行時刻幅$\Delta t= 0.0$[s]を観察する．先行時間幅の定義より$\Delta t= 0.0$から$X(t)=Y(t)$のため，プロットGround TruthはCurrent Velocityと一致している．予測された結果$f_{0.0}(X(t))$が$X(t)$に漸近していれば予測器の獲得が失敗していないことを示すコントロールデータとなりうる．図\ref{fig:velocity-result}上段から，$f_{0.0}(X(t))$(プロットPredicted)は概ね$Y(t)$(プロットGround Truth)と一致しており，期待する結果であるといえる．
First, observe the preceding time width $ \Delta t = 0.0 $ [s] at the top of the Figure~\ref{fig:velocity-result}. Because of $ \Delta t = 0.0 $ to $ X (t) = Y (t) $ from the definition of the preceding time width, the plot Ground Truth is consistent with the Current Velocity. If the predicted result $ f_ {0.0} (X (t)) $ is asymptotic to $ X (t) $, it can be control data indicating that predictor acquisition has not failed. $ F_ {0.0} (X (t)) $ (plot Predicted) is consistent with $ Y (t) $ (plot Ground Truth) from the upper part of the Figure~\ref{fig:velocity-result} It can be said that it is a result.

%次に図\ref{fig:velocity-result}中段の先行時刻幅$\Delta t= 0.5$[s]を観察する．同図の$X(t)$が$Y(t+0.5)$と位相差を約$\pi$もつことから，1歩先の運動予測のための評価用データ群であることが確認できる．同様に$f_{0.5}(X(t))$と$Y(t+0.5)$を比較すると，図\ref{fig:velocity-result}中段に黒矢印で示した時刻付近で右左折を意味する速度変化がGround Truthに沿って予測されることがわかった．これは図中の$f_{0.5}(X(t))$(プロットPredicted)は$X(t)$の速度と反して$Y(t+0.5)$に漸近した変動を示していることから，1歩先の頭頂部速度予測可能性を示すものであるといえる．
Next, observe the preceding time width $ \Delta t = 0.5 $ [s] at the middle of the Figure~\ref{fig:velocity-result}. Since $ X (t) $ in the figure has a phase difference of about $ \pi $ with $ Y (t + 0.5) $, it can be confirmed that it is an evaluation data group for one-step ahead motion prediction . Similarly, when you compare $ f_ {0.5} (X (t)) $ and $ Y (t + 0.5) $, you turn right / left at the middle of the Figure~\ref{fig:velocity-result} near the time indicated by the black arrow It turns out that the meaningful speed change is predicted along the Ground Truth. This means that $ f_ {0.5} (X (t)) $ (plot Predicted) in the figure shows asymptotic fluctuation to $ Y (t + 0.5) $ contrary to the speed of $ X (t) $ , It can be said that it shows the possibility of predicting head top speed one step ahead.

%最後に図\ref{fig:velocity-result}下段の先行時刻幅$\Delta t= 1.1$[s]を観察する．同様に$X(t)$が$Y(t+1.1)$と位相差を約$2\pi$もつことから，2歩先の評価用データ群であることが確認できる．さらに$f_{1.1}(X(t))$と$Y(t+1.1)$を比較すると，$f_{1.1}(X(t))$のデータが右左折を意味する速度変動を予測すべき時刻から大きく遅れて予測されていることがわかった．すなわち，2歩先の頭頂部速度予測可能性は今回用いたデータセット群では確認することができなかった．
Finally, observe the preceding time width $ \Delta t = 1.1 $ [s] at the bottom of the Figure~\ref{fig:velocity-result}. Likewise, since $ X (t) $ has a phase difference of about $ 2 \pi $ with $ Y (t + 1.1) $, it can be confirmed that it is a data group for evaluation two steps ahead. Furthermore, when comparing $ f_ {1.1} (X (t)) $ and $ Y (t + 1.1) $, it is predicted that the data of $ f_ {1.1} (X (t)) $ represents a right / It was found that it was expected to be greatly delayed from the time it should be. In other words, we could not confirm the possibility of predicting parietal region velocity two steps ahead in the data set group used this time.


%\subsection{歩行軌跡の推定と評価}
\subsection{Estimation and evaluation of walking locus}

%時刻$t$における頭頂部速度の推定結果は前述の通り正規化されていることから，式(\ref{eq:average})と式(\ref{eq:standardDeviation})で求めた系列$m$内平均$\overline{\check{v}_{m}} $と標準偏差$\check{s}_m$を用いた逆変換を行い実世界座標系での速度ベクトルを導出する．そこで式(\ref{eq:integration})により初期座標を基準とした時間積分を行い頭頂部軌跡を求めた．ただし$\delta t = 1/300 $[fps] である．
{\bf ****** NEED TO REVISE *****}Since the estimation result of the parietal velocity at time $ t $ is normalized as described above, the series $ m $(\ref {eq:average}) and expression (\ref {eq:standardDeviation}) We perform inverse transformation using inner average $ \overline {\check {v} _ {m}} $ and standard deviation $ \check {s} _ m $ and derive the velocity vector in the real world coordinate system. Therefore, time integration based on the initial coordinates was performed by the equation (\ref {eq:integration}), and the head top trajectory was obtained. However, $ \delta t = 1/300 $ [fps].

\begin{equation}
\vec{p}(t) = \sum^{t}_{t=1}(\check{s}_m  v_{m,t} +  \overline{\check{v}_{m}})  \delta t+ \vec{p}_0(t_0)
\label{eq:integration}
\end{equation}


%図\ref{fig:0.0sec}〜図\ref{fig:1.1sec}はそれぞれ先行時間幅$\Delta  t =\{0.0, \ 0.5,\  1.1\} $[s]ごとに図\ref{fig:velocity-result}の予測された時系列速度(プロットPredicted)を式(\ref{eq:integration})を用いて頭頂部軌跡としてプロットした結果の天面図である．細実線が$Y(t+\Delta t)$の期待する結果であり，太実線が$f_{\Delta t}(X(t))$の予測結果を示している．歩行者は図の左側から右側に向かって歩行を開始し原点付近で五分岐していることから，各歩行軌跡5条件に従った歩行した様子が観察できる．
Figure~\ref{fig:0.0sec} ~ Figure~\ref{fig:1.1sec} are shown in the figure for each time period $ \Delta t = \{0.0, \ 0.5, \ 1.1 \} $ [s] The plot of the predicted time series velocity (plot Predicted) of Figure~\ref{fig: velocity-result} as the top of the head using the formula (\ref {eq:integration}). The thin solid line is the expected result of $ Y (t + \Delta t) $, and the bold solid line shows the prediction result of $ f_ {\Delta t} (X (t)) $. Since the pedestrian started walking from the left side to the right side of the figure and five branches near the origin, it is possible to observe the state of walking according to each of the five walking loci conditions.

%図\ref{fig:0.0sec}〜図\ref{fig:1.1sec}から，先行時刻幅が増加するに従い，期待する頭部軌跡から予測された軌跡が逸脱していく様子が観察された．$\Delta t = 0.0$[s]条件である図\ref{fig:0.0sec}は期待する結果と予測された軌跡は一致しており，$\Delta t = 0.5$[s]条件である図\ref{fig-0.5sec}は最大約500[mm]程度の位置誤差が確認された．また$\Delta t = 1.1$[s]条件である図\ref{fig:1.1sec}は，右左折条件で特に概ね2歩分に相当する約1000[mm]の位置誤差が原点付近で観察された．これは前節で述べた通り予測された速度変動の時刻が期待する時刻で観測されなかったことに起因する．

From Figure~\ref{fig:0.0sec} ~ Figure~\ref{fig:1.1sec}, it is observed that the predicted trajectory deviates from the expected head trajectory as the advance time width increases. $ \Delta t = 0.0 $ [s] The figure \ref{fig:0.0sec} which is the condition is the expected result and the predicted trajectory are in agreement and is the condition of $ \Delta t = 0.5 $ [s] A position error of about 500 [mm] at the maximum was confirmed in Figure~\ref{fig:0.5sec}. In addition, the figure \ref{fig:1.1sec}, which is the condition of $ \Delta t = 1.1 $ [s], shows that a position error of about 1000 [mm] corresponding to roughly two steps, It was done. This is due to the fact that the time of the predicted speed fluctuation was not observed at the expected time as described in the previous section.

%\begin{figure}[tb]
%  \begin{center}
%    \includegraphics*[width=60mm]{fig/shift_0.0sec/trail.eps}
%  \end{center}
%  \vspace*{-10mm}
%  \caption{$\Delta t$ = 0.0[s]}
%  \label{fig:0.0sec}
%%\end{figure}

\begin{figure*}
\centering
  \includegraphics[width=180mm]{fig/trail_all.eps}
  \caption{$\Delta t$ = 1.1[s]}~\label{fig:1.1sec}
\end{figure*}

% Balancing columns in a ref list is a bit of a pain because you
% either use a hack like flushend or balance, or manually insert
% a column break.  http://www.tex.ac.uk/cgi-bin/texfaq2html?label=balance
% multicols doesn't work because we're already in two-column mode,
% and flushend isn't awesome, so I choose balance.  See this
% for more info: http://cs.brown.edu/system/software/latex/doc/balance.pdf
%
% Note that in a perfect world balance wants to be in the first
% column of the last page.
%
% If balance doesn't work for you, you can remove that and
% hard-code a column break into the bbl file right before you
% submit:
%
% http://stackoverflow.com/questions/2149854/how-to-manually-equalize-columns-
% in-an-ieee-paper-if-using-bibtex
%
% Or, just remove \balance and give up on balancing the last page.
%
\balance{}


%\section{Conclusion}
%
%It is important that you write for the SIGCHI audience. Please read
%previous years' proceedings to understand the writing style and
%conventions that successful authors have used. It is particularly
%important that you state clearly what you have done, not merely what
%you plan to do, and explain how your work is different from previously
%published work, i.e., the unique contribution that your work makes to
%the field. Please consider what the reader will learn from your
%submission, and how they will find your work useful. If you write with
%these questions in mind, your work is more likely to be successful,
%both in being accepted into the conference, and in influencing the
%work of our field.
%
%\section{むすび}%%%%%%%%%%%%%%%%%%%%
\section{Conclusion}%%%%%%%%%%%%%%%%%%%%
%ヒトの歩行運動は，突発的な感覚入力への姿勢反射応答の潜時が約２歩であることが知られている．そのため歩行を実時間で誘導するためには，現在の歩行運動状態から２歩先行した歩行運動を実時間で予測し続ける必要がある．そこで本研究では多層パーセプトロンを用いた実時間歩行運動予測を行い，直進・右左折を含む5種の歩行運動に対し，１歩先行した歩行予測を実現した．
It is known that the walking motion of humans is about 2 steps in latency of attitude reflection response to sudden sensory input. Therefore, in order to induce walking in real time, it is necessary to continue to predict walking exercise two steps ahead of the current locomotion state in real time. Therefore, in this study, real time walking motion prediction using multilayered perceptron was performed, and walking prediction a step ahead of five walking exercises including straight ahead, right turn and left turn was realized.

%今後の課題として現在は被験者数が1名に限られており教師データ数が少ない．また本報告は訂正的な評価が主体となっており，定量的な評価が求められる．さらに入出力層設計の妥当性に対する評価を行う必要がある．
Currently, the number of subjects is limited to one person and the number of teacher data is small as a future task. This report is mainly based on corrective evaluation, and quantitative evaluation is required. Furthermore, it is necessary to evaluate the validity of the input / output layer design.


\section{Acknowledgments}
%
Sample text: We thank all the volunteers, and all publications support
and staff, who wrote and provided helpful comments on previous
versions of this document. Authors 1, 2, and 3 gratefully acknowledge
the grant from NSF (\#1234--2012--ABC). \textit{This whole paragraph is
  just an example.}


%%%%%%%%%%%%%%%%%%%%%%





\subsection{Title and Authors}

Your paper's title, authors and affiliations should run across the
full width of the page in a single column 17.8 cm (7 in.) wide.  The
title should be in Helvetica or Arial 18-point bold.  Authors' names
should be in Times New Roman or Times Roman 12-point bold, and
affiliations in 12-point regular.  

See \texttt{{\textbackslash}author} section of this template for
instructions on how to format the authors. For more than three
authors, you may have to place some address information in a footnote,
or in a named section at the end of your paper. Names may optionally
be placed in a single centered row instead of at the top of each
column. Leave one 10-point line of white space below the last line of
affiliations.

\subsection{Abstract and Keywords}

Every submission should begin with an abstract of about 150 words,
followed by a set of Author Keywords and ACM Classification
Keywords. The abstract and keywords should be placed in the left
column of the first page under the left half of the title. The
abstract should be a concise statement of the problem, approach, and
conclusions of the work described. It should clearly state the paper's
contribution to the field of HCI\@.

\subsection{Normal or Body Text}

Please use a 10-point Times New Roman or Times Roman font or, if this
is unavailable, another proportional font with serifs, as close as
possible in appearance to Times Roman 10-point. Other than Helvetica
or Arial headings, please use sans-serif or non-proportional fonts
only for special purposes, such as source code text.

\subsection{First Page Copyright Notice}
This template include a sample ACM copyright notice at the bottom of
page 1, column 1.  Upon acceptance, you will be provided with the
appropriate copyright statement and unique DOI string for publication.
Accepted papers will be distributed in the conference
publications. They will also be placed in the ACM Digital Library,
where they will remain accessible to thousands of researchers and
practitioners worldwide. See
\url{http://acm.org/publications/policies/copyright_policy} for the
ACM's copyright and permissions policy.

\subsection{Subsequent Pages}

On pages beyond the first, start at the top of the page and continue
in double-column format.  The two columns on the last page should be
of equal length.

\begin{figure}
\centering
  \includegraphics[width=0.9\columnwidth]{figures/sigchi-logo}
  \caption{Insert a caption below each figure. Do not alter the
    Caption style.  One-line captions should be centered; multi-line
    should be justified. }~\label{fig:figure1}
\end{figure}

\subsection{References and Citations}

Use a numbered list of references at the end of the article, ordered
alphabetically by last name of first author, and referenced by numbers
in
brackets~\cite{acm_categories,ethics,Klemmer:2002:WSC:503376.503378}.
Your references should be published materials accessible to the
public. Internal technical reports may be cited only if they are
easily accessible (i.e., you provide the address for obtaining the
report within your citation) and may be obtained by any reader for a
nominal fee. Proprietary information may not be cited. Private
communications should be acknowledged in the main text, not referenced
(e.g., ``[Borriello, personal communication]'').

References should be in ACM citation format:
\url{http://acm.org/publications/submissions/latex_style}. This
includes citations to internet
resources~\cite{acm_categories,cavender:writing,CHINOSAUR:venue,psy:gangnam}
according to ACM format, although it is often appropriate to include
URLs directly in the text, as above.


% Use a numbered list of references at the end of the article, ordered
% alphabetically by first author, and referenced by numbers in
% brackets~\cite{ethics, Klemmer:2002:WSC:503376.503378,
%   Mather:2000:MUT, Zellweger:2001:FAO:504216.504224}. For papers from
% conference proceedings, include the title of the paper and an
% abbreviated name of the conference (e.g., for Interact 2003
% proceedings, use \textit{Proc. Interact 2003}). Do not include the
% location of the conference or the exact date; do include the page
% numbers if available. See the examples of citations at the end of this
% document. Within this template file, use the \texttt{References} style
% for the text of your citation.

% Your references should be published materials accessible to the
% public.  Internal technical reports may be cited only if they are
% easily accessible (i.e., you provide the address for obtaining the
% report within your citation) and may be obtained by any reader for a
% nominal fee.  Proprietary information may not be cited. Private
% communications should be acknowledged in the main text, not referenced
% (e.g., ``[Robertson, personal communication]'').

\begin{table}
  \centering
  \begin{tabular}{l r r r}
    % \toprule
    & & \multicolumn{2}{c}{\small{\textbf{Test Conditions}}} \\
    \cmidrule(r){3-4}
    {\small\textit{Name}}
    & {\small \textit{First}}
      & {\small \textit{Second}}
    & {\small \textit{Final}} \\
    \midrule
    Marsden & 223.0 & 44 & 432,321 \\
    Nass & 22.2 & 16 & 234,333 \\
    Borriello & 22.9 & 11 & 93,123 \\
    Karat & 34.9 & 2200 & 103,322 \\
    % \bottomrule
  \end{tabular}
  \caption{Table captions should be placed below the table. We
    recommend table lines be 1 point, 25\% black. Minimize use of
    table grid lines.}~\label{tab:table1}
\end{table}

\section{Sections}

The heading of a section should be in Helvetica or Arial 9-point bold,
all in capitals. Sections should \textit{not} be numbered.

\subsection{Subsections}

Headings of subsections should be in Helvetica or Arial 9-point bold
with initial letters capitalized.  For sub-sections and
sub-subsections, a word like \emph{the} or \emph{of} is not
capitalized unless it is the first word of the heading.
%
%\subsubsection{Sub-subsections}
%
%Headings for sub-subsections should be in Helvetica or Arial 9-point
%italic with initial letters capitalized.  Standard
%\texttt{{\textbackslash}section}, \texttt{{\textbackslash}subsection},
%and \texttt{{\textbackslash}subsubsection} commands will work fine in
%this template.
%
%\section{Figures/Captions}
%
%Place figures and tables at the top or bottom of the appropriate
%column or columns, on the same page as the relevant text (see
%Figure~\ref{fig:figure1}). A figure or table may extend across both
%columns to a maximum width of 17.78 cm (7 in.).

%\begin{figure*}
%  \centering
%  \includegraphics[width=1.75\columnwidth]{figures/map}
%  \caption{In this image, the map maximizes use of space. You can make
%    figures as wide as you need, up to a maximum of the full width of
%    both columns. Note that \LaTeX\ tends to render large figures on a
%    dedicated page. Image: \ccbynd~ayman on
%    Flickr.}~\label{fig:figure2}
%\end{figure*}
%
%Captions should be Times New Roman or Times Roman 9-point bold.  They
%should be numbered (e.g., ``Table~\ref{tab:table1}'' or
%``Figure~\ref{fig:figure1}''), centered and placed beneath the figure
%or table.  Please note that the words ``Figure'' and ``Table'' should
%be spelled out (e.g., ``Figure'' rather than ``Fig.'') wherever they
%occur. Figures, like Figure~\ref{fig:figure2}, may span columns and
%all figures should also include alt text for improved accessibility.
%Papers and notes may use color figures, which are included in the page
%limit; the figures must be usable when printed in black-and-white in
%the proceedings.
%
%The paper may be accompanied by a short video figure up to five
%minutes in length. However, the paper should stand on its own without
%the video figure, as the video may not be available to everyone who
%reads the paper.  

%\subsection{Inserting Images}
%When possible, include a vector formatted graphic (i.e. PDF or EPS).
%When including bitmaps,  use an image editing tool to resize the image
%at the appropriate printing resolution (usually 300 dpi).
%
%\section{Quotations}
%Quotations may be italicized when \textit{``placed inline''} (Anab,
%23F).
%
%\begin{quote}
%Longer quotes, when placed in their own paragraph, need not be
%italicized or in quotation marks when indented (Ramon, 39M).  
%\end{quote}
%
%\section{Language, Style, and Content}
%
%The written and spoken language of SIGCHI is English. Spelling and
%punctuation may use any dialect of English (e.g., British, Canadian,
%US, etc.) provided this is done consis- tently. Hyphenation is
%optional. To ensure suitability for an international audience, please
%pay attention to the following:
%
%\begin{itemize}
%\item Write in a straightforward style.
%\item Try to avoid long or complex sentence structures.
%\item Briefly define or explain all technical terms that may be
%  unfamiliar to readers.
%\item Explain all acronyms the first time they are used in your
%  text---e.g., ``Digital Signal Processing (DSP)''.
%\item Explain local references (e.g., not everyone knows all city
%  names in a particular country).
%\item Explain ``insider'' comments. Ensure that your whole audience
%  understands any reference whose meaning you do not describe (e.g.,
%  do not assume that everyone has used a Macintosh or a particular
%  application).
%\item Explain colloquial language and puns. Understanding phrases like
%  ``red herring'' may require a local knowledge of English.  Humor and
%  irony are difficult to translate.
%\item Use unambiguous forms for culturally localized concepts, such as
%  times, dates, currencies, and numbers (e.g., ``1--5--97'' or
%  ``5/1/97'' may mean 5 January or 1 May, and ``seven o'clock'' may
%  mean 7:00 am or 19:00). For currencies, indicate equivalences:
%  ``Participants were paid {\fontfamily{txr}\selectfont \textwon}
%  25,000, or roughly US \$22.''
%\item Be careful with the use of gender-specific pronouns (he, she)
%  and other gendered words (chairman, manpower, man-months). Use
%  inclusive language that is gender-neutral (e.g., she or he, they,
%  s/he, chair, staff, staff-hours, person-years). See the
%  \textit{Guidelines for Bias-Free Writing} for further advice and
%  examples regarding gender and other personal
%  attributes~\cite{Schwartz:1995:GBF}. Be particularly aware of
%  considerations around writing about people with disabilities.
%\item If possible, use the full (extended) alphabetic character set
%  for names of persons, institutions, and places (e.g.,
%  Gr{\o}nb{\ae}k, Lafreni\'ere, S\'anchez, Nguy{\~{\^{e}}}n,
%  Universit{\"a}t, Wei{\ss}enbach, Z{\"u}llighoven, \r{A}rhus, etc.).
%  These characters are already included in most versions and variants
%  of Times, Helvetica, and Arial fonts.
%\end{itemize}

%\section{Accessibility}
%The Executive Council of SIGCHI has committed to making SIGCHI
%conferences more inclusive for researchers, practitioners, and
%educators with disabilities. As a part of this goal, the all authors
%are asked to work on improving the accessibility of their
%submissions. Specifically, we encourage authors to carry out the
%following five steps:
%\begin{enumerate}
%\item Add alternative text to all figures
%\item Mark table headings
%\item Add tags to the PDF
%\item Verify the default language
%\item Set the tab order to ``Use Document Structure''
%\end{enumerate}
%For more information and links to instructions and resources, please
%see: \url{http://chi2016.acm.org/accessibility}.  The
%\texttt{{\textbackslash}hyperref} package allows you to create well tagged PDF files,
%please see the preamble of this template for an example.
%
%\section{Page Numbering, Headers and Footers}
%Your final submission should not contain footer or header information
%at the top or bottom of each page. Specifically, your final submission
%should not include page numbers. Initial submissions may include page
%numbers, but these must be removed for camera-ready. Page numbers will
%be added to the PDF when the proceedings are assembled.

%\section{Producing and Testing PDF Files}
%
%We recommend that you produce a PDF version of your submission well
%before the final deadline.  Your PDF file must be ACM DL
%Compliant. The requirements for an ACM Compliant PDF are available at:
%{\url{http://www.sheridanprinting.com/typedept/ACM-distilling-settings.htm}}.
%
%Test your PDF file by viewing or printing it with the same software we
%will use when we receive it, Adobe Acrobat Reader Version 10. This is
%widely available at no cost. Note that most
%reviewers will use a North American/European version of Acrobat
%reader, so please check your PDF accordingly.
%
%When creating your PDF from Word, ensure that you generate a tagged
%PDF from improved accessibility. This can be done by using the Adobe
%PDF add-in, also called PDFMaker. Select Acrobat | Preferences from
%the ribbon and ensure that ``Enable Accessibility and Reflow with
%tagged Adobe PDF'' is selected. You can then generate a tagged PDF by
%selecting ``Create PDF'' from the Acrobat ribbon.
%
%\section{Conclusion}
%
%It is important that you write for the SIGCHI audience. Please read
%previous years' proceedings to understand the writing style and
%conventions that successful authors have used. It is particularly
%important that you state clearly what you have done, not merely what
%you plan to do, and explain how your work is different from previously
%published work, i.e., the unique contribution that your work makes to
%the field. Please consider what the reader will learn from your
%submission, and how they will find your work useful. If you write with
%these questions in mind, your work is more likely to be successful,
%both in being accepted into the conference, and in influencing the
%work of our field.
%
%\section{Acknowledgments}
%
%Sample text: We thank all the volunteers, and all publications support
%and staff, who wrote and provided helpful comments on previous
%versions of this document. Authors 1, 2, and 3 gratefully acknowledge
%the grant from NSF (\#1234--2012--ABC). \textit{This whole paragraph is
%  just an example.}

% Balancing columns in a ref list is a bit of a pain because you
% either use a hack like flushend or balance, or manually insert
% a column break.  http://www.tex.ac.uk/cgi-bin/texfaq2html?label=balance
% multicols doesn't work because we're already in two-column mode,
% and flushend isn't awesome, so I choose balance.  See this
% for more info: http://cs.brown.edu/system/software/latex/doc/balance.pdf
%
% Note that in a perfect world balance wants to be in the first
% column of the last page.
%
% If balance doesn't work for you, you can remove that and
% hard-code a column break into the bbl file right before you
% submit:
%
% http://stackoverflow.com/questions/2149854/how-to-manually-equalize-columns-
% in-an-ieee-paper-if-using-bibtex
%
% Or, just remove \balance and give up on balancing the last page.
%
%\balance{}

%\section{References Format}
%Your references should be published materials accessible to the
%public. Internal technical reports may be cited only if they are
%easily accessible and may be obtained by any reader for a nominal
%fee. Proprietary information may not be cited. Private communications
%should be acknowledged in the main text, not referenced (e.g.,
%[Golovchinsky, personal communication]). References must be the same
%font size as other body text. References should be in alphabetical
%order by last name of first author. Use a numbered list of references
%at the end of the article, ordered alphabetically by last name of
%first author, and referenced by numbers in brackets. For papers from
%conference proceedings, include the title of the paper and the name of
%the conference. Do not include the location of the conference or the
%exact date; do include the page numbers if available. 
%
%References should be in ACM citation format:
%\url{http://www.acm.org/publications/submissions/latex_style}.  This
%includes citations to Internet
%resources~\cite{CHINOSAUR:venue,cavender:writing,psy:gangnam}
%according to ACM format, although it is often appropriate to include
%URLs directly in the text, as above. Example reference formatting for
%individual journal articles~\cite{ethics}, articles in conference
%proceedings~\cite{Klemmer:2002:WSC:503376.503378},
%books~\cite{Schwartz:1995:GBF}, theses~\cite{sutherland:sketchpad},
%book chapters~\cite{winner:politics}, an entire journal
%issue~\cite{kaye:puc},
%websites~\cite{acm_categories,cavender:writing},
%tweets~\cite{CHINOSAUR:venue}, patents~\cite{heilig:sensorama}, 
%games~\cite{supermetroid:snes}, and
%online videos~\cite{psy:gangnam} is given here.  See the examples of
%citations at the end of this document and in the accompanying
%\texttt{BibTeX} document. This formatting is a edited version of the
%format automatically generated by the ACM Digital Library
%(\url{http://dl.acm.org}) as ``ACM Ref.'' DOI and/or URL links are
%optional but encouraged as are full first names. Note that the
%Hyperlink style used throughout this document uses blue links;
%however, URLs in the references section may optionally appear in
%black.

% BALANCE COLUMNS
\balance{}

% REFERENCES FORMAT
% References must be the same font size as other body text.
\bibliographystyle{SIGCHI-Reference-Format}
\bibliography{CHI2018_furukawa}

\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
